{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41187aff8c27893b9f65afec51598f32231da9de"
   },
   "source": [
    "# Ensemble Collaborative filtering for personalized project recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25712c7acbf1f09aef00c5be6f87863085975e26"
   },
   "source": [
    "## Kernel - 2 for DonorsChoose.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "578bf76cbdd622df6647181ccd4f468abcf79070"
   },
   "source": [
    "## Why this problem is different then a standard recommendation engine problem ?\n",
    "In normal recommendation system problem, we have a recommend a movie/item to a user and we want this movie/item to be as personalized as possible. If we take an example of Netflix recommendations, for each account/user Netflix will recommend a bunch of movies/shows (say 20-25 in number, scope of view is limited as if we suggest 1000 shows donor won't scroll and look at them) and hope that these recommendation are such that user buy one or more of these shows. But this problem is different, First of all in this problem, one needs to recommend donor of each new projects (its the other way around) and second, there is no limitation how many donors should be recommended for a new project. i.e. for a new project, 10000 emails can be send targeting 10000 different individuals. For one individual there is only one email. Then Why use the standard way of k recommended donors for each project and then judge on recall@k and precision@k, rather design a new method and evaluate the success rate of recommendation. In this kernel we will design a method which is memory efficient, runs very fast and give us a set of donors for each project. We will test it on the dataset and see what is the success rate if we would have emailed the recommended donors. \n",
    "\n",
    "**Why not email all the donors for each project ?**\n",
    "- It costs to email each donor so if one is Emailing 5000 donors for one project, it will cost around 5000 x 0.003 dollar i.e. 15 Dollar, so if we don't use this targeting and Email all 2m donors, ~6000 dollars and which can be way greater than the actual donation received for that project. ( **and offcourse we will get multiple donations and might get 20x the total project cost, we may still be profitable**)\n",
    "- But that way donor will get irritated and won't pay much attention if we continue to do so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11c6e6727ac874159bd4bdfac10593d3a5acbe47"
   },
   "source": [
    "## Why ensemble CF taking Donor vs projects attributes one by one \n",
    "### Because the order of SVD on donor vs project matrix is O(min{mn2,m2n}) and it will take huge space and time in calculation if done on all dataset in one go\n",
    "Whenever we use collaborative filtering on data which is very large as the data provided by DonorsChoose, it is very difficult to give space optimized solution. The Donors vs Project matrix is very large in this case, One will need good capacity systems to compute the SVD for Donors vs Projects matrix. It made me wonder if we can do it in limited space and time and still get comparable results. This will be my attempt to develop a solution which will decompose multiple Donors vs Projects_attribute matrices and apply a filter on them to finally provide recommendations.\n",
    "\n",
    "- **Approach** - Each project has different attributes, we can create categories based on each attribute and apply collaborative filtering on Donors vs project_attribute_1, then Donors vs project_attribute_2 and so on. We will get multiple sets of Donors which should be emailed about new projects. The purpose is not to do less targeted campaigning but to systematically solve the problem of a large matrix. That's why we will take the intersection of all the sets and take the common in all sets will be our list of Donors and we will send email to them about a new project.\n",
    "\n",
    "- **How it is helping** - Each project has different different attribute (say 3 attribute) A1, A2 and A3, and they have 100, 100 and 50 categories in them, so if one wants to use all three categories then there will be 100*100*50 i.e. 500k columns will be there in Donors vs Project(categories) matrix and SVD on this will be very tough in comparision to SVD if we are using one attribute at a time i.e. Donors vs Project_attribute (A1, 100 columns), so we will be doing in a sequencial manner. In addition to that the order of SVD is  O(min{mn2,m2n}) so making small matrix will make it super fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc2e391e08a11cc4178cc386b2c61624556eb83c"
   },
   "source": [
    "## Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4536ea7c78d9727eb541648416c668ba05e861c1"
   },
   "source": [
    "![](https://lh3.googleusercontent.com/-JcJKzgv_9Ek/WyoYdjrA5vI/AAAAAAAAvcQ/dZFjJ0EcHSUzvw0joJcjdvUGfqNn45zKwCL0BGAYYCw/h1101/2018-06-20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "a82d911f6ce0ce23a0964340ab1c2451f6353b37",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD, evaluate\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import time\n",
    "import datetime\n",
    "from sys import getsizeof\n",
    "from scipy.sparse.linalg import svds\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "output_notebook()\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.tools as tls\n",
    "from matplotlib_venn import venn3\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from functools import reduce\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "31401339f2ba5e933b586ad62dd5a15f0a7a94eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "donations = pd.read_csv(\"../input/Donations.csv\", encoding='latin-1')\n",
    "donors = pd.read_csv(\"../input/Donors.csv\", encoding='latin-1')\n",
    "projects = pd.read_csv(\"../input/Projects.csv\", encoding='latin-1')\n",
    "resources = pd.read_csv(\"../input/Resources.csv\", encoding='latin-1')\n",
    "schools = pd.read_csv(\"../input/Schools.csv\", encoding='latin-1')\n",
    "teachers = pd.read_csv(\"../input/Teachers.csv\", encoding='latin-1')\n",
    "# We won't be doing EDA here as EDA as been done in Kernel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "60037a8c7950a80c466b7e324cf77116290742c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merging projects and school file\n",
    "projects = projects.merge(schools, left_on='School ID',\n",
    "                          right_on='School ID', how='left')\n",
    "# merging projects and donations file\n",
    "projects = projects.merge(donations, left_on='Project ID',\n",
    "                           right_on='Project ID', how='left')\n",
    "# merging projects and donations file\n",
    "projects = projects.merge(donors, left_on='Donor ID',\n",
    "                           right_on='Donor ID', how='left')\n",
    "master_df = projects.merge(teachers, left_on='Teacher ID',\n",
    "                           right_on='Teacher ID', how='left')\n",
    "\n",
    "\n",
    "\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a501ea704d7b8a5882e6bd66e91988643805a35a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_list = ['Project Type', 'School State',\n",
    "                 'Project Subject Category Tree',\n",
    "                 'Project Grade Level Category',\n",
    "                 'School Metro Type']\n",
    "\n",
    "\n",
    "def Reco_CF(args):\n",
    "    \"\"\"Function to calculate the ensembled filtered CF based recommendations\n",
    "        Input -\n",
    "            Args dict\n",
    "            args[0] => df on which one wants to do the filtering\n",
    "            args[1] => variable to be used for category/item in donor category matrix\n",
    "            args[2] => sample size to be used in passed dataframe \n",
    "                       -1 for complete df\n",
    "            args[3] => factors for SV decomposition \n",
    "        Output -\n",
    "            CF_pred_df => Donor vs category matrix (numpy array)\n",
    "        \n",
    "        \n",
    "        Example - \n",
    "        cf_matrix = Reco_CF(args)\n",
    "            \n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    df = args[0]\n",
    "    var = args[1]\n",
    "    sample_size = args[2]\n",
    "    factors = args[3]\n",
    "    print(\"CF for donors vs {}\".format(var))\n",
    "    df2 = pd.DataFrame(df.groupby(['Donor ID', var])['Donation Amount'\n",
    "                       ].sum())\n",
    "    df2.reset_index(inplace=True)\n",
    "    df2['log_amount'] = list(map(np.log, df2['Donation Amount'] + 1))\n",
    "\n",
    "    # Specifying sample size and making pivot\n",
    "\n",
    "    if sample_size == -1:\n",
    "        size = df2.shape[0]\n",
    "    else:\n",
    "        size = sample_size\n",
    "    donors_projects_pivot_matrix_df = \\\n",
    "        df2.head(size).pivot(index='Donor ID', columns=var,\n",
    "                             values='log_amount').fillna(0)\n",
    "    print('Pivot formed')\n",
    "\n",
    "    donors_ids = list(donors_projects_pivot_matrix_df.index)\n",
    "\n",
    "    # Collaborative filtering making vactors using matrix of donor vs projects categories\n",
    "\n",
    "    donors_projects_pivot_matrix = \\\n",
    "        donors_projects_pivot_matrix_df.as_matrix()\n",
    "\n",
    "    # Performs matrix factorization of the original donor item matrix\n",
    "\n",
    "    (U, sigma, Vt) = svds(donors_projects_pivot_matrix, k=factors)\n",
    "    sigma = np.diag(sigma)\n",
    "    all_donor_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "    cf_preds_df = pd.DataFrame(all_donor_predicted_ratings,\n",
    "                               columns=donors_projects_pivot_matrix_df.columns,\n",
    "                               index=donors_ids).transpose()\n",
    "\n",
    "    print('CF done')\n",
    "    return cf_preds_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "066d0bbdead7f2b9c0f84aa878daec6bc6147701"
   },
   "source": [
    "## projects features we will be using for ensemble collaborative filtering \n",
    "                    A) 'Project Type', \n",
    "                    B) 'School State',\n",
    "                    C) 'Project Subject Category Tree',\n",
    "                    D) 'Project Grade Level Category',\n",
    "                    E) 'School Metro Type'\n",
    "                    \n",
    "### Other features can also be used like after digitizing like  \n",
    "                    F) '% lunch\n",
    "                    G) 'Project cost, log of project cost\n",
    "### Other variables which can be used -\n",
    "                    H) 'School district'\n",
    "                    I) 'Teacher's Prefix'\n",
    "                    J) 'Donor's State'\n",
    "                    K) 'Donor is Teacher'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "936bfac6997fa1d367c3ecd6d7a2b9a08430d35b"
   },
   "source": [
    "## Define prediction ensemble CF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0177fc66c0e3ca283564894e0ec2d8ec4177c52e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(\n",
    "    engine,\n",
    "    test,\n",
    "    var_,\n",
    "    n,\n",
    "    ):\n",
    "    \"\"\"Function to generate test predictions for CF_engine passed\n",
    "        Input - \n",
    "            engine - recommendation engine\n",
    "            test - Test dataset which has same variables that train dataset has\n",
    "            var_ - variables which was used in passed engine for making Donors\n",
    "                   vs Project attribute matrix\n",
    "            n - Number of recpmmedation per project attribute\n",
    "        Output -\n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    # test set prep - making pivot\n",
    "\n",
    "    def pred_n(row, var_=var_):\n",
    "        \"\"\"function to predict the n most probable donors\"\"\"\n",
    "\n",
    "        var = row[var_]\n",
    "\n",
    "        # engine_row = engine.loc[var]\n",
    "        # print(engine_row.dtype)\n",
    "\n",
    "        pred_ = engine.sort_values(var, axis=1,\n",
    "                                   ascending=False).loc[var].index[0:n]\n",
    "\n",
    "        # print(pred_)\n",
    "\n",
    "        pred_list = list(pred_)\n",
    "        return pred_list\n",
    "\n",
    "    test['pred_' + var_ + '_list'] = test.apply(lambda row: \\\n",
    "            pred_n(row), axis=1)\n",
    "    return test\n",
    "\n",
    "\n",
    "def Ensemble_CF(\n",
    "    df,\n",
    "    list_var,\n",
    "    test,\n",
    "    n,\n",
    "    sample_size,\n",
    "    ):\n",
    "    \"\"\"Function to do the ensamble CF\n",
    "        Input - \n",
    "               df - dataframe usually master df\n",
    "               list_var - list of variables to be used\n",
    "               test- test set having projects information\n",
    "               n - number of donors to be predicted from each CF run\n",
    "               Sample_size - size of the sample: -1 for full sample\n",
    "        Output - \n",
    "                test - test set having prediction using all attributes passed\n",
    "                engine_list - list of engines as np array\n",
    "    \"\"\"\n",
    "    text_file = open(\"logfile.txt\", \"w\")\n",
    "    engine_list = []\n",
    "    for var_ in list_var:\n",
    "        start = time.time()\n",
    "        \n",
    "        text_file.write(\"=\"*80)\n",
    "        text_file.write(\"Models specs are \")\n",
    "        text_file.write('\\n')\n",
    "        text_file.write(\"Sample size is \"+ str(sample_size))\n",
    "        text_file.write('\\n' )\n",
    "        text_file.write(\"CF for donors vs \"+str(var_))\n",
    "        text_file.write('\\n' )\n",
    "        factors = 2\n",
    "        args = {}\n",
    "        args[0] = df\n",
    "        args[1] = var_\n",
    "        args[2] = sample_size\n",
    "        args[3] = factors\n",
    "        engine = Reco_CF(args)\n",
    "        end_1 = time.time()\n",
    "        text_file.write('Engine made in ' + str(end_1 - start)+ \" sec\")\n",
    "        print('Engine made in ' + str(end_1 - start)+ \" sec\")\n",
    "        test = predictions(engine, test, var_, n)\n",
    "        end = time.time()\n",
    "        text_file.write('\\n' )\n",
    "        text_file.write('predictions Done in ' + str(end - end_1)+ \" sec\")\n",
    "        text_file.write('\\n' )\n",
    "        print('predictions Done in ' + str(end - end_1)+ \" sec\")\n",
    "        engine_list.append(engine)\n",
    "    text_file.write('Ensemble Collaborative filtering done')\n",
    "    text_file.close()\n",
    "    return (test, engine_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "424317a8523842ad8e7a1c88e139688b91d84a12"
   },
   "source": [
    "## Testing Ensemble collaborative filtering on an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60417096aebb50de92c9fd92bb9a4213fb8a0817",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_list = [\n",
    "    'Project Type',\n",
    "    'School State',\n",
    "    'Project Subject Category Tree',\n",
    "    'Project Grade Level Category',\n",
    "    'School Metro Type',\n",
    "    'Teacher Prefix',\n",
    "    ]\n",
    "k = 5000\n",
    "(test_ensemble, engine_list) = Ensemble_CF(master_df, sequence_list,\n",
    "        master_df[6000:6100], k, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae4cd88f47783fcefe8ab69168e57b6c9ff665a1"
   },
   "source": [
    "### Parallelized functions if we need to run it on large number of projects (maybe in future or for testing on full data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab0d1a20bdace6b97dbe9aeb7bbadd3608aaf8b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiprocessing pool functions \n",
    "from multiprocessing import Pool\n",
    "\n",
    "def predictions(args):\n",
    "    \"\"\"Function to generate test predictions for CF_engine passed\n",
    "        Input - \n",
    "            engine - recommendation engine\n",
    "            test - Test dataset which has same variables that train dataset has\n",
    "            var_ - variables which was used in passed engine for making Donors \n",
    "                   vs Project attribute matrix\n",
    "            n - Number of recpmmedation per project attribute\n",
    "        Output -\n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    engine = args[0]\n",
    "    test = args[1]\n",
    "    var_ = args[2]\n",
    "    n = args[3]\n",
    "\n",
    "    # test set prep - making pivot\n",
    "\n",
    "    def pred_n(row, var_=var_):\n",
    "        \"\"\"function to predict the n most probable donors\"\"\"\n",
    "        var = row[var_]\n",
    "        # engine_row = engine.loc[var]\n",
    "        # print(engine_row.dtype)\n",
    "        pred_ = engine.sort_values(var, axis=1,\n",
    "                                   ascending=False).loc[var].index[0:n]\n",
    "\n",
    "        # print(pred_)\n",
    "        pred_list = list(pred_)\n",
    "        return pred_list\n",
    "    test['pred_' + var_ + '_list'] = test.apply(lambda row: \\\n",
    "            pred_n(row), axis=1)\n",
    "    return test\n",
    "\n",
    "\n",
    "def Ensemble_CF_mp(df, list_var, test, n, sample_size):\n",
    "    \"\"\"Function to do the ensamble CF\"\"\"\n",
    "    engine_list =[]\n",
    "    pool = Pool(processes=3)\n",
    "    for var_ in list_var:\n",
    "        start = time.time()\n",
    "        factors = 2\n",
    "        args = {}\n",
    "        args[0] = df\n",
    "        args[1] = var_\n",
    "        args[2] = sample_size\n",
    "        args[3] = factors\n",
    "        engine = Reco_CF(args)\n",
    "        #engine = Reco_CF(df,  var_,sample_size, factors = 2)\n",
    "        print(\"Engine is {}\".format(getsizeof(engine/1024)))\n",
    "        end_1 = time.time()\n",
    "        print(\"Engine made \"+ str(end_1 -start))\n",
    "        # pool_processes = 2\n",
    "        chunk_size = 50\n",
    "        test.reset_index(inplace = True)\n",
    "        h = 0\n",
    "        test_ = []\n",
    "        start = 0\n",
    "        for h in list(range((test.shape[0]//chunk_size))):\n",
    "            if h != test.shape[0]//chunk_size:\n",
    "                test_.append(test.loc[start:(start+chunk_size)])\n",
    "                start = start+chunk_size\n",
    "                #print(start)\n",
    "            else:\n",
    "                test_.append(test.loc[start:(test.shape[0]-1)]) \n",
    "        print(test_.__len__())\n",
    "        h =test_.__len__()\n",
    "        print(h)\n",
    "        #print(zip([engine]*h, test_, [var_]*h, [n]*h))\n",
    "        test_2 = pool.map(predictions, zip([engine]*h, test_, [var_]*h, [n]*h))\n",
    "        print(test_2.__len__())\n",
    "        \n",
    "        #test = predictions(engine, test, var_, n)\n",
    "        end = time.time()\n",
    "        print(\"Engine made \"+ str(end-end_1))\n",
    "        engine_list.append(engine)\n",
    "    pool.close()    \n",
    "    return(test_2, engine_list)\n",
    "\n",
    "MULTIPROCESSING = False\n",
    "if MULTIPROCESSING:\n",
    "    sequence_list = ['Project Type', 'School State',\n",
    "                     'Project Subject Category Tree']\n",
    "    k = 5000\n",
    "    (test_ensemble, engine_list) = Ensemble_CF_mp(master_df,\n",
    "            sequence_list, master_df[6000:6100], k, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "f2a67cd6271a69fc60fee8c073798a7d5ea216be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to find the intersection off all predictions \n",
    "\n",
    "\n",
    "def intersection_of_ensemble(row):\n",
    "    cols = list(row.index)\n",
    "    pred_cols = [x for x in cols if x[0:5] == 'pred_']\n",
    "    for i in list(range(pred_cols.__len__() - 1)):\n",
    "        if i == 0:\n",
    "            temp_set = \\\n",
    "                set(row[pred_cols[i]]).intersection(set(row[pred_cols[i\n",
    "                    + 1]]))\n",
    "        else:\n",
    "            temp_set = temp_set.intersection(set(row[pred_cols[i + 1]]))\n",
    "    return list(temp_set)\n",
    "\n",
    "\n",
    "test_ensemble['ensemble_pred_list'] = test_ensemble.apply(lambda row: \\\n",
    "        intersection_of_ensemble(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "9aba9c6db9ab54eb962231e7e8f908aec21272b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ensemble.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c446c94e96b57f26581d24dedb234db63400ae2"
   },
   "source": [
    "## Showing it on venn diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dcd8a9d3752f9ddf4dd47565263ed6537507d7db"
   },
   "source": [
    "#### Venn diagram showing intersection of 3 out of 6 variables\n",
    "Here we are using 6 variables for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "8ee461d0d964084bac870b925750c5f7ab01582e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# venn diagram for visualisation\n",
    "\n",
    "p = 6005\n",
    "sequence_list1 = ['Project Type', 'School State',\n",
    "                  'Project Subject Category Tree']\n",
    "set_list = []\n",
    "for var in sequence_list1:\n",
    "    var_new = 'pred_' + var + '_list'\n",
    "    temp = set(test_ensemble.loc[p][var_new])\n",
    "    set_list.append(temp)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "venn3(set_list, ('pred_Project Type_list', 'pred_School State_list',\n",
    "      'pred_Project Subject Category Tree_list'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b68e84942df7d2985453b109a6f0af46e531369"
   },
   "source": [
    "#### Taking intersection of predictions on rest of the 3 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "c421bf01095ab1844d618238ac83a1125f1e6f57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_list2 = ['Project Grade Level Category', 'School Metro Type',\n",
    "                  'Teacher Prefix']\n",
    "p = 6005\n",
    "set_list = []\n",
    "for var in sequence_list2:\n",
    "    var_new = 'pred_' + var + '_list'\n",
    "    temp = set(test_ensemble.loc[p][var_new])\n",
    "    set_list.append(temp)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "venn3(set_list, ('Project Grade Level Category', 'School Metro Type',\n",
    "      'Teacher Prefix'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed20350661c7a3d9eaab9908bea882d10760ff17"
   },
   "source": [
    "#### Taking intersection of prediction from last 2 sets from by taking intersections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "add96923af4769798f866051c62dfe7eafbbee43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 6005\n",
    "set_1 = set(test_ensemble.loc[p]['pred_Project Type_list'\n",
    "            ]).intersection(set(test_ensemble.loc[p]['pred_School State_list'\n",
    "                            ]))\n",
    "set_2 = \\\n",
    "    set_1.intersection(set(test_ensemble.loc[p]['pred_Project Subject Category Tree_list'\n",
    "                       ]))\n",
    "set_2\n",
    "\n",
    "p = 6005\n",
    "set_3 = \\\n",
    "    set(test_ensemble.loc[p]['pred_Project Grade Level Category_list'\n",
    "        ]).intersection(set(test_ensemble.loc[p]['pred_School Metro Type_list'\n",
    "                        ]))\n",
    "set_4 = \\\n",
    "    set_1.intersection(set(test_ensemble.loc[p]['pred_Teacher Prefix_list'\n",
    "                       ]))\n",
    "set_4\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "venn2([set_2, set_4], ('Intersection of seq_list1',\n",
    "      'Intersection of seq_list2'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "d2bfdf7a9f288b8a57b848e84cbb87c399fedb13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy Check\n",
    "# Explain why we are not using recall and precision\n",
    "\n",
    "\n",
    "def reco_success_rate(row):\n",
    "    \"\"\"Function to calculate how many reco must have succeeded \n",
    "       if we used this model\n",
    "        input - df - test_ensemble dataframe\n",
    "                k - number of reco to conside\n",
    "        Ouutput - % successful reco email fire\n",
    "    \"\"\"\n",
    "\n",
    "    success = 0\n",
    "    if row['Donor ID'] in row['ensemble_pred_list']:\n",
    "        success = 1\n",
    "    return success\n",
    "\n",
    "\n",
    "test_ensemble['success'] = test_ensemble.apply(lambda row: \\\n",
    "        reco_success_rate(row), axis=1)\n",
    "\n",
    "\n",
    "def Mean_success_rate(df):\n",
    "    \"\"\"Function to calculate the success rate\"\"\"\n",
    "    df['success'] = df.apply(lambda row: reco_success_rate(row), axis=1)\n",
    "    success = 1.0 * df['success'].sum()\n",
    "    total = df.shape[0]\n",
    "    return np.float(success / total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f13592faad2db30ade052ea7e9ef79cd7f0d316"
   },
   "source": [
    "## Mean Success Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "5f0ce94ba878689fbcba08a9ee6aa87175b2291e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSR plot based on number of recommendation\n",
    "MSR = Mean_success_rate(test_ensemble)\n",
    "MSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "536eac670f9c03c8c794272328b31fc804b6ed30",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unsuccessful_attempt = (100- MSR*100)\n",
    "successful_attempt = (MSR*100)\n",
    "import plotly.plotly as py\n",
    "init_notebook_mode()\n",
    "trace0 = go.Bar(\n",
    "    x=['successful Email attempt', 'unsuccessful Email attempt'],\n",
    "    y=[successful_attempt, unsuccessful_attempt],\n",
    "    marker=dict(\n",
    "        color=['rgba(20,204,204,1)', 'rgba(222,45,38,0.8)'],\n",
    "        line=dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=0.5,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "layout = go.Layout(\n",
    "    title='Successful vs unsuccessful Email attempts',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='color-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dc67bfbe7b558ddcc8876cdda73af787c64257a"
   },
   "source": [
    "## Accuracy variation based on k \n",
    "**k is number we set to predict from each CF but after intersection in general final recommendations are 1/4 of set k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "5febee6e9af8f5e50d3300595a9c472cadb4120e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy variation based on emails\n",
    "\n",
    "list_of_k = [\n",
    "    1000,\n",
    "    2000,\n",
    "    4000,\n",
    "    8000,\n",
    "    16000,\n",
    "    ]\n",
    "MSR_for_k = []\n",
    "Deciding_k = False\n",
    "if Deciding_k:\n",
    "    sequence_list = [\n",
    "        'Project Type',\n",
    "        'School State',\n",
    "        'Project Subject Category Tree',\n",
    "        'Project Grade Level Category',\n",
    "        'School Metro Type',\n",
    "        'Teacher Prefix',\n",
    "        ]\n",
    "    for k in list_of_k:\n",
    "        print('+=' * 50)\n",
    "        (test_ensemble, engine_list) = Ensemble_CF(master_df,\n",
    "                sequence_list, master_df[6000:6100], k, -1)\n",
    "        test_ensemble['ensemble_pred_list'] = \\\n",
    "            test_ensemble.apply(lambda row: \\\n",
    "                                intersection_of_ensemble(row), axis=1)\n",
    "        MSR = Mean_success_rate(test_ensemble)\n",
    "        MSR_for_k.append(MSR)\n",
    "        del test_ensemble\n",
    "        del engine_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0519cb46297979fbf47a1bb4159e56ff79d1eb39"
   },
   "source": [
    "### Plot of success rate vs k (k for each CF and is not the final number of recommended donors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4dbe0434992bb2f46b11778755a5352a0066cfee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reseults have been copied here for plotting\n",
    "list_of_k = [\n",
    "    1000,\n",
    "    2000,\n",
    "    4000,\n",
    "    8000,\n",
    "    16000,\n",
    "    ]\n",
    "MSR_for_k = [0.11, 0.15, 0.19, 0.23, 0.27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "288cb5640cca370b75c9a6b1649499430049cc60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_x = np.array(list_of_k)\n",
    "_y0 = np.array(MSR_for_k)\n",
    "\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = _x,\n",
    "    y = _y0,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Success_Rate'\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace0]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "iplot(fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e10ebfe358bf7e68e81fadfa2b1394af7e27efea"
   },
   "source": [
    "### Link to next kernel \n",
    "link - https://www.kaggle.com/maheshdadhich/behaviour-based-content-clustering\n",
    "\n",
    "#### Thanks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef9279d574c74f42d5a43a60f3eaac1b631761aa",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
